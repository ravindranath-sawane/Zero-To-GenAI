{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6860834",
   "metadata": {},
   "source": [
    "## 1. ğŸ”§ The Setup\n",
    "\n",
    "Before we start experimenting with prompts, we need to:\n",
    "1. Load our API key from the `.env` file\n",
    "2. Initialize the ChatOpenAI model\n",
    "\n",
    "### Prerequisites\n",
    "Make sure you have:\n",
    "- Created a `.env` file with your `OPENAI_API_KEY`\n",
    "- Installed the required packages: `pip install langchain-openai python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a1559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# SETUP: Load environment and initialize LLM\n",
    "# ===========================================\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Modern LangChain imports (2025 standard)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify the key is loaded\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"âœ… OPENAI_API_KEY loaded successfully!\")\n",
    "else:\n",
    "    print(\"âŒ ERROR: OPENAI_API_KEY not found. Please check your .env file.\")\n",
    "\n",
    "# Initialize the ChatOpenAI model\n",
    "# Using gpt-4o-mini for cost-effective learning (you can change to gpt-4o for better results)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7  # Balanced creativity\n",
    ")\n",
    "\n",
    "print(f\"ğŸ¤– Model initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to make our examples cleaner\n",
    "def ask(prompt: str, system_prompt: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Send a prompt to the LLM and return the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The user's question or instruction\n",
    "        system_prompt: Optional system message to set AI behavior\n",
    "    \n",
    "    Returns:\n",
    "        The AI's response as a string\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if system_prompt:\n",
    "        messages.append(SystemMessage(content=system_prompt))\n",
    "    \n",
    "    messages.append(HumanMessage(content=prompt))\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "# Quick test\n",
    "print(\"ğŸ§ª Quick test:\")\n",
    "print(ask(\"Say 'Hello, Prompt Engineering!' and nothing else.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc2206",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ğŸ¯ Zero-Shot vs Few-Shot Prompting\n",
    "\n",
    "### What's the Difference?\n",
    "\n",
    "| Approach | Description | When to Use |\n",
    "|----------|-------------|-------------|\n",
    "| **Zero-Shot** | Ask directly without examples | Simple tasks, general questions |\n",
    "| **Few-Shot** | Provide examples before asking | Specific formats, complex patterns |\n",
    "\n",
    "### The Problem with Zero-Shot\n",
    "\n",
    "Sometimes, when we need a **very specific output format**, Zero-Shot prompting fails because the model interprets our request differently than we intended.\n",
    "\n",
    "Let's see this in action! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# ZERO-SHOT: Asking without examples\n",
    "# ===========================================\n",
    "\n",
    "zero_shot_prompt = \"\"\"\n",
    "Extract the product name and price from this text and format it as:\n",
    "PRODUCT: [name] | PRICE: [amount]\n",
    "\n",
    "Text: \"The new iPhone 15 Pro is available for $999 at all Apple stores.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ”´ ZERO-SHOT ATTEMPT\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Prompt:\", zero_shot_prompt.strip())\n",
    "print(\"\\nğŸ“¤ Response:\")\n",
    "print(ask(zero_shot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c91f70",
   "metadata": {},
   "source": [
    "### ğŸ¤” What Happened?\n",
    "\n",
    "The Zero-Shot response might:\n",
    "- Add extra explanation we didn't ask for\n",
    "- Use slightly different formatting\n",
    "- Include unnecessary text\n",
    "\n",
    "Now let's try **Few-Shot** prompting by showing the model exactly what we want! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# FEW-SHOT: Providing examples first\n",
    "# ===========================================\n",
    "\n",
    "few_shot_prompt = \"\"\"\n",
    "Extract the product name and price from text. Follow the exact format shown in the examples.\n",
    "\n",
    "Example 1:\n",
    "Text: \"Get the Samsung Galaxy S24 for just $799!\"\n",
    "Output: PRODUCT: Samsung Galaxy S24 | PRICE: $799\n",
    "\n",
    "Example 2:\n",
    "Text: \"The MacBook Air M3 starts at $1,099 with free shipping.\"\n",
    "Output: PRODUCT: MacBook Air M3 | PRICE: $1,099\n",
    "\n",
    "Example 3:\n",
    "Text: \"Sony WH-1000XM5 headphones are on sale for $349.99.\"\n",
    "Output: PRODUCT: Sony WH-1000XM5 | PRICE: $349.99\n",
    "\n",
    "Now extract from this text:\n",
    "Text: \"The new iPhone 15 Pro is available for $999 at all Apple stores.\"\n",
    "Output:\"\"\"\n",
    "\n",
    "print(\"ğŸŸ¢ FEW-SHOT ATTEMPT (with 3 examples)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“¤ Response:\")\n",
    "print(ask(few_shot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cd3d3",
   "metadata": {},
   "source": [
    "### âœ… Few-Shot Success!\n",
    "\n",
    "By providing examples, we:\n",
    "- Showed the exact format we wanted\n",
    "- Eliminated ambiguity\n",
    "- Got consistent, clean output\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: The more consistent your examples, the better the model follows your pattern. Use 2-5 examples for best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a523b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ğŸ§  Chain of Thought (CoT) Prompting\n",
    "\n",
    "### The Problem: LLMs Can Be Lazy Thinkers\n",
    "\n",
    "LLMs are trained to predict the most likely next token. For complex reasoning tasks, they might jump to a \"common\" answer without actually thinking through the logic.\n",
    "\n",
    "### The Solution: \"Let's think step by step\"\n",
    "\n",
    "By asking the model to reason through the problem, we force it to:\n",
    "1. Break down the problem\n",
    "2. Consider each part\n",
    "3. Arrive at the correct answer\n",
    "\n",
    "Let's see this with a classic trick question! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# THE TRICK QUESTION\n",
    "# ===========================================\n",
    "\n",
    "# This is a classic logic puzzle that trips up LLMs (and humans!)\n",
    "# The correct answer: Still 4 hours! Shirts dry in parallel, not sequentially.\n",
    "\n",
    "trick_question = \"\"\"\n",
    "If it takes 4 hours to dry 5 shirts in the sun, how long will it take to dry 10 shirts?\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ§© THE TRICK QUESTION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Question: {trick_question.strip()}\")\n",
    "print(\"\\nğŸ¤” Think about it... What's the correct answer?\")\n",
    "print(\"   (Hint: Do shirts dry one at a time, or all together?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# WITHOUT Chain of Thought\n",
    "# ===========================================\n",
    "\n",
    "print(\"ğŸ”´ WITHOUT Chain of Thought\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "naive_prompt = \"If it takes 4 hours to dry 5 shirts in the sun, how long will it take to dry 10 shirts? Give me just the answer.\"\n",
    "\n",
    "print(\"ğŸ“¤ Response:\")\n",
    "print(ask(naive_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf64d85",
   "metadata": {},
   "source": [
    "### ğŸ¤” Did it Fall for the Trap?\n",
    "\n",
    "The model might have answered **8 hours** (wrong!) because:\n",
    "- It pattern-matched to simple math: 10 shirts = 2Ã— shirts, so 2Ã— time\n",
    "- It didn't think about the **physics** of drying\n",
    "\n",
    "**The correct answer is 4 hours** because:\n",
    "- Shirts dry in **parallel** (all at the same time), not one after another\n",
    "- If you have enough space, 10 shirts dry just as fast as 5!\n",
    "\n",
    "Now let's use Chain of Thought! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# WITH Chain of Thought\n",
    "# ===========================================\n",
    "\n",
    "print(\"ğŸŸ¢ WITH Chain of Thought\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cot_prompt = \"\"\"\n",
    "If it takes 4 hours to dry 5 shirts in the sun, how long will it take to dry 10 shirts?\n",
    "\n",
    "Let's think step by step:\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“¤ Response:\")\n",
    "print(ask(cot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8d308",
   "metadata": {},
   "source": [
    "### âœ… Chain of Thought Success!\n",
    "\n",
    "By adding **\"Let's think step by step\"**, the model:\n",
    "1. Considered what \"drying\" actually means\n",
    "2. Realized shirts dry in parallel\n",
    "3. Arrived at the correct answer: **4 hours**\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: Use CoT for math problems, logic puzzles, multi-step reasoning, and any task where the \"obvious\" answer might be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ec90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# BONUS: Another CoT Example\n",
    "# ===========================================\n",
    "\n",
    "print(\"ğŸ BONUS: Another Chain of Thought Example\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Another classic trick question\n",
    "bonus_cot_prompt = \"\"\"\n",
    "A farmer has 17 sheep. All but 9 die. How many sheep are left?\n",
    "\n",
    "Let's think step by step:\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“¤ Response:\")\n",
    "print(ask(bonus_cot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b58be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ğŸ­ System Prompts: Controlling AI Personality\n",
    "\n",
    "### What is a System Prompt?\n",
    "\n",
    "A **System Prompt** is a special instruction that sets the AI's:\n",
    "- **Personality** (formal, casual, funny)\n",
    "- **Role** (expert, assistant, character)\n",
    "- **Constraints** (what to do and not do)\n",
    "\n",
    "It's like giving the AI a character sheet before the conversation starts!\n",
    "\n",
    "### The Message Types\n",
    "\n",
    "```python\n",
    "SystemMessage  â†’ Sets the AI's behavior/personality (invisible to user)\n",
    "HumanMessage   â†’ The user's input\n",
    "AIMessage      â†’ The AI's response\n",
    "```\n",
    "\n",
    "Let's have some fun with different personalities! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577bb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# PERSONALITY 1: The Pirate ğŸ´â€â˜ ï¸\n",
    "# ===========================================\n",
    "\n",
    "pirate_system = \"\"\"\n",
    "You are a friendly pirate captain named Captain CodeBeard. \n",
    "You speak in pirate dialect, using words like \"Arrr!\", \"ye\", \"matey\", \"treasure\", and \"seas\".\n",
    "You're helpful but always stay in character.\n",
    "End every response with a pirate phrase.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ´â€â˜ ï¸ PERSONALITY: Captain CodeBeard the Pirate\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "user_question = \"Can you explain what an API is?\"\n",
    "print(f\"ğŸ‘¤ User: {user_question}\")\n",
    "print(f\"\\nğŸ´â€â˜ ï¸ Captain CodeBeard:\")\n",
    "print(ask(user_question, system_prompt=pirate_system))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# PERSONALITY 2: Sarcastic Tech Support ğŸ˜\n",
    "# ===========================================\n",
    "\n",
    "sarcastic_system = \"\"\"\n",
    "You are a sarcastic tech support agent who has seen it all.\n",
    "You're actually helpful and give correct answers, but you can't resist adding dry humor and light sarcasm.\n",
    "You often reference common tech support frustrations.\n",
    "Keep responses concise but entertaining.\n",
    "Never be mean, just playfully sarcastic.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ˜ PERSONALITY: Sarcastic Tech Support\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "user_question = \"My code isn't working. What should I do?\"\n",
    "print(f\"ğŸ‘¤ User: {user_question}\")\n",
    "print(f\"\\nğŸ˜ Tech Support:\")\n",
    "print(ask(user_question, system_prompt=sarcastic_system))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# PERSONALITY 3: Wise Yoda ğŸ§˜\n",
    "# ===========================================\n",
    "\n",
    "yoda_system = \"\"\"\n",
    "You are Yoda from Star Wars. You speak in Yoda's distinctive inverted sentence structure.\n",
    "You are wise and give thoughtful advice about programming and technology.\n",
    "Occasionally reference the Force, the Jedi way, or Star Wars concepts as metaphors.\n",
    "Keep responses relatively short but profound.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ§˜ PERSONALITY: Wise Yoda\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "user_question = \"How do I become a better programmer?\"\n",
    "print(f\"ğŸ‘¤ User: {user_question}\")\n",
    "print(f\"\\nğŸ§˜ Yoda:\")\n",
    "print(ask(user_question, system_prompt=yoda_system))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# COMPARISON: Same Question, Different Personalities\n",
    "# ===========================================\n",
    "\n",
    "print(\"ğŸ­ COMPARISON: Same Question, Different Personalities\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_question = \"What is Python?\"\n",
    "print(f\"\\nğŸ“ Question: '{comparison_question}'\\n\")\n",
    "\n",
    "personalities = [\n",
    "    (\"ğŸ´â€â˜ ï¸ Pirate\", pirate_system),\n",
    "    (\"ğŸ˜ Sarcastic\", sarcastic_system),\n",
    "    (\"ğŸ§˜ Yoda\", yoda_system),\n",
    "]\n",
    "\n",
    "for name, system in personalities:\n",
    "    print(f\"{name}:\")\n",
    "    print(ask(comparison_question, system_prompt=system))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc382f3",
   "metadata": {},
   "source": [
    "### âœ… System Prompts: Key Takeaways\n",
    "\n",
    "1. **Set the stage**: System prompts define who the AI \"is\" before the conversation\n",
    "2. **Be specific**: The more detailed your system prompt, the more consistent the behavior\n",
    "3. **Include constraints**: Tell the AI what NOT to do as well as what to do\n",
    "4. **Test and iterate**: Different phrasings produce different results\n",
    "\n",
    "> ğŸ’¡ **Pro Tip**: In production apps, system prompts are where you define your AI assistant's personality, capabilities, and safety guardrails!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8934d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Summary\n",
    "\n",
    "### What You Learned Today\n",
    "\n",
    "âœ… **Setup**\n",
    "- Use `langchain_openai` with `ChatOpenAI` (modern 2025 syntax)\n",
    "- Load API keys securely with `python-dotenv`\n",
    "\n",
    "âœ… **Zero-Shot vs Few-Shot**\n",
    "- Zero-Shot: Ask directly (works for simple tasks)\n",
    "- Few-Shot: Provide examples (essential for specific formats)\n",
    "- Rule: When format matters, show don't tell!\n",
    "\n",
    "âœ… **Chain of Thought (CoT)**\n",
    "- LLMs can be \"lazy thinkers\" and pattern-match to wrong answers\n",
    "- Magic phrase: \"Let's think step by step\"\n",
    "- Use for: Math, logic puzzles, multi-step reasoning\n",
    "\n",
    "âœ… **System Prompts**\n",
    "- Define AI personality, role, and constraints\n",
    "- Be specific and include what NOT to do\n",
    "- Essential for building consistent AI applications\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Next Steps\n",
    "\n",
    "In the next module, we'll explore **API Interactions** â€” calling OpenAI and Google Gemini APIs directly to build real applications!\n",
    "\n",
    "Happy prompting! ğŸ¯"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
